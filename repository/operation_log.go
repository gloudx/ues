package repository

import (
	"context"
	"encoding/json"
	"fmt"
	"time"

	"ues/blockstore"

	"github.com/ipfs/go-cid"
	"github.com/ipld/go-ipld-prime/datamodel"
	"github.com/ipld/go-ipld-prime/node/basicnode"
)

// OperationLog представляет компонент для логирования всех операций в репозитории.
// Он обеспечивает аудит, мониторинг и возможность восстановления состояния системы.
//
// Основные возможности:
// - Логирование всех CRUD операций с записями
// - Поддержка различных типов операций (создание, обновление, удаление)
// - Конфигурируемая политика хранения логов
// - Поддержка потокового чтения логов в реальном времени
// - Возможность фильтрации операций по типу, времени, пользователю
// - Автоматическая очистка старых записей согласно политике хранения
//
// Примеры использования:
// - Аудит действий пользователей в социальной сети
// - Отладка проблем с данными
// - Мониторинг производительности операций
// - Восстановление последовательности изменений
type OperationLog struct {
	bs         blockstore.Blockstore // Хранилище блоков для персистентного хранения log записей в формате IPLD
	collection string                // Имя коллекции, в которой хранятся log записи (по умолчанию "_operation_log")
	config     *OperationLogConfig   // Конфигурация поведения логгера (политики хранения, размеры, фильтры)
}

// OperationLogConfig определяет параметры конфигурации для OperationLog.
// Позволяет настроить поведение логгера под конкретные требования приложения.
//
// Основные настройки:
// - Выбор коллекции для хранения логов
// - Политика хранения (сколько времени хранить логи)
// - Ограничения на размер записей
// - Фильтрация типов операций для логирования
// - Настройки потокового режима
// - Оптимизация производительности через батчинг
//
// Пример конфигурации для production:
//
//	config := &OperationLogConfig{
//	    Collection:      "audit_logs",
//	    RetentionPeriod: 365 * 24 * time.Hour, // 1 год
//	    MaxLogSize:      10 * 1024 * 1024,     // 10MB
//	    EnabledOps:      []string{"put_record", "delete_record"},
//	    StreamEnabled:   true,
//	    BatchSize:       1000,
//	}
type OperationLogConfig struct {
	Collection      string        `json:"collection"`       // Имя коллекции для хранения log записей (default: "_operation_log")
	RetentionPeriod time.Duration `json:"retention_period"` // Период хранения логов до автоматического удаления (default: 30 days)
	MaxLogSize      int64         `json:"max_log_size"`     // Максимальный размер одной log записи в байтах (default: 1MB)
	EnabledOps      []string      `json:"enabled_ops"`      // Список включенных типов операций для логирования (default: ["all"])
	StreamEnabled   bool          `json:"stream_enabled"`   // Включить режим потокового чтения логов в реальном времени (default: false)
	BatchSize       int           `json:"batch_size"`       // Размер batch для групповой записи логов для оптимизации производительности (default: 100)
}

// OperationType представляет тип операции, которая выполняется в системе.
// Используется для категоризации и фильтрации операций в логах.
// Каждый тип операции имеет специфическое назначение и контекст использования.
type OperationType string

// Константы типов операций для различных сценариев использования системы.
// Каждая константа документирует конкретные случаи применения и примеры.
const (
	// OpPutRecord - операция создания или полного обновления записи в коллекции.
	//
	// Когда используется:
	// - Создание новых постов, комментариев, профилей пользователей
	// - Обновление существующих записей с изменением данных
	// - Импорт данных из внешних источников
	// - Восстановление записей из резервных копий
	//
	// Примеры применения:
	// - Пользователь публикует новый пост в социальной сети
	// - Обновление информации профиля пользователя
	// - Добавление нового товара в каталог интернет-магазина
	// - Создание нового события в календаре
	//
	// Логируемые данные: collection, rkey, record_cid, размер записи
	OpPutRecord OperationType = "put_record"

	// OpDeleteRecord - операция полного удаления записи из коллекции.
	//
	// Когда используется:
	// - Удаление постов по запросу пользователя
	// - Модерация контента (удаление нарушающих правила записей)
	// - Очистка устаревших или неактуальных данных
	// - GDPR compliance - удаление персональных данных
	//
	// Примеры применения:
	// - Пользователь удаляет свой пост или комментарий
	// - Модератор удаляет спам или неподходящий контент
	// - Автоматическое удаление временных записей
	// - Удаление аккаунта пользователя со всеми данными
	//
	// Логируемые данные: collection, rkey, причина удаления
	OpDeleteRecord OperationType = "delete_record"

	// OpPutCollection - операция создания новой коллекции или обновления схемы коллекции.
	//
	// Когда используется:
	// - Добавление новых типов данных в систему
	// - Развертывание новых функций приложения
	// - Создание пользовательских коллекций
	// - Миграция схем данных
	//
	// Примеры применения:
	// - Добавление нового типа записей "События" в социальную сеть
	// - Создание коллекции для хранения настроек приложения
	// - Добавление поддержки новых форматов медиа-контента
	// - Создание коллекций для A/B тестирования
	//
	// Логируемые данные: имя коллекции, схема, версия
	OpPutCollection OperationType = "put_collection"

	// OpDeleteCollection - операция удаления коллекции и всех связанных данных.
	//
	// Когда используется:
	// - Удаление устаревших или неиспользуемых типов данных
	// - Очистка системы от экспериментальных функций
	// - Реструктуризация архитектуры данных
	// - Завершение жизненного цикла функций
	//
	// Примеры применения:
	// - Удаление коллекции временных A/B тестов
	// - Очистка данных завершенных экспериментов
	// - Удаление устаревших форматов данных
	// - Реорганизация структуры коллекций
	//
	// Логируемые данные: имя коллекции, количество удаленных записей
	OpDeleteCollection OperationType = "delete_collection"

	// OpUpdateSchema - операция обновления схемы существующей коллекции.
	//
	// Когда используется:
	// - Добавление новых полей в существующие типы записей
	// - Изменение валидации или ограничений полей
	// - Эволюция структуры данных без потери существующих записей
	// - Оптимизация схем для новых требований
	//
	// Примеры применения:
	// - Добавление поля "геолокация" к постам
	// - Изменение максимальной длины текста в комментариях
	// - Добавление поддержки новых типов медиа в записях
	// - Обновление схемы профиля пользователя
	//
	// Логируемые данные: коллекция, старая схема, новая схема, тип изменения
	OpUpdateSchema OperationType = "update_schema"

	// OpReindex - операция переиндексации данных для оптимизации поиска и производительности.
	//
	// Когда используется:
	// - После изменения схемы коллекции
	// - Оптимизация производительности поиска
	// - Восстановление поврежденных индексов
	// - Плановое обслуживание системы
	//
	// Примеры применения:
	// - Переиндексация после добавления нового поля для поиска
	// - Восстановление индексов после сбоя системы
	// - Оптимизация индексов для улучшения производительности
	// - Обновление полнотекстовых индексов
	//
	// Логируемые данные: коллекция, тип индекса, количество обработанных записей, время выполнения
	OpReindex OperationType = "reindex"

	// OpMaintenance - операции планового и внепланового обслуживания системы.
	//
	// Когда используется:
	// - Автоматическая очистка временных данных
	// - Компактификация базы данных
	// - Резервное копирование данных
	// - Проверка целостности данных
	//
	// Примеры применения:
	// - Ежедневная очистка логов старше retention period
	// - Еженедельная дефрагментация базы данных
	// - Проверка и восстановление поврежденных записей
	// - Архивирование старых неактивных данных
	//
	// Логируемые данные: тип обслуживания, затронутые коллекции, результаты
	OpMaintenance OperationType = "maintenance"

	// OpReplication - операции синхронизации и репликации данных между узлами системы.
	//
	// Когда используется:
	// - Синхронизация данных между master и replica узлами
	// - Резервное копирование на удаленные серверы
	// - Распределение данных в кластере
	// - Восстановление данных после сбоев
	//
	// Примеры применения:
	// - Синхронизация изменений между географически распределенными серверами
	// - Создание резервных копий критически важных данных
	// - Балансировка нагрузки через репликацию данных
	// - Восстановление узла из репликационных источников
	//
	// Логируемые данные: источник, назначение, объем данных, статус синхронизации
	OpReplication OperationType = "replication"
)

// LogEntry представляет одну запись в логе операций.
// Содержит полную информацию о выполненной операции для целей аудита,
// мониторинга производительности и отладки системы.
//
// Структура записи спроектирована для:
// - Обеспечения полной трассируемости операций
// - Поддержки различных сценариев анализа и отчетности
// - Совместимости с системами мониторинга и аналитики
// - Эффективного хранения в IPLD формате
//
// Жизненный цикл записи:
// 1. Создание при начале операции (заполнение основных полей)
// 2. Обновление при завершении (добавление результата и времени выполнения)
// 3. Сериализация в IPLD узел для хранения
// 4. Индексация для быстрого поиска и анализа
// 5. Автоматическое удаление по истечении retention period
type LogEntry struct {
	OperationID   string                 `json:"operation_id"`   // Уникальный идентификатор операции для корреляции связанных событий (UUID или аналогичный)
	Timestamp     time.Time              `json:"timestamp"`      // Точное время начала операции в UTC для хронологического упорядочивания
	OperationType OperationType          `json:"operation_type"` // Тип выполняемой операции для категоризации и фильтрации логов
	Actor         string                 `json:"actor"`          // DID (Decentralized Identifier) пользователя, инициировавшего операцию
	Collection    string                 `json:"collection"`     // Имя коллекции, над которой выполняется операция (например, "app.bsky.feed.post")
	RKey          string                 `json:"rkey"`           // Ключ записи в коллекции для идентификации конкретного элемента данных
	RecordCID     *cid.Cid               `json:"record_cid"`     // Content Identifier (CID) записи в IPFS для верификации целостности данных
	Metadata      map[string]interface{} `json:"metadata"`       // Дополнительные контекстные данные специфичные для типа операции (размер данных, источник, теги)
	Result        string                 `json:"result"`         // Результат выполнения операции: "success" для успешных, "error" для неуспешных операций
	Error         string                 `json:"error"`          // Детальное сообщение об ошибке, если операция завершилась неуспешно (пусто для успешных операций)
	Duration      time.Duration          `json:"duration"`       // Общее время выполнения операции для анализа производительности и выявления узких мест
}

// DefaultOperationLogConfig создает конфигурацию по умолчанию для OperationLog.
// Предоставляет разумные значения по умолчанию для большинства случаев использования.
//
// Значения по умолчанию:
// - Collection: "_operation_log" - специальная системная коллекция для логов
// - RetentionPeriod: 30 дней - баланс между хранением истории и экономией места
// - MaxLogSize: 1MB - предотвращает создание чрезмерно больших записей
// - EnabledOps: ["all"] - логирование всех типов операций
// - StreamEnabled: false - потоковый режим отключен для экономии ресурсов
// - BatchSize: 100 - оптимальный размер для большинства рабочих нагрузок
//
// Рекомендации по настройке:
// - Для production увеличьте RetentionPeriod до 90-365 дней
// - Для высоконагруженных систем увеличьте BatchSize до 500-1000
// - Включите StreamEnabled только если нужен real-time мониторинг
// - Настройте EnabledOps для логирования только критически важных операций
//
// Возвращает:
//
//	Указатель на структуру OperationLogConfig с настройками по умолчанию
func DefaultOperationLogConfig() *OperationLogConfig {
	return &OperationLogConfig{
		Collection:      "_operation_log",
		RetentionPeriod: 30 * 24 * time.Hour, // 30 days
		MaxLogSize:      1024 * 1024,         // 1MB
		EnabledOps:      []string{"all"},
		StreamEnabled:   false,
		BatchSize:       100,
	}
}

// NewOperationLog создает новый экземпляр OperationLog с указанной конфигурацией.
// Конструктор выполняет инициализацию всех необходимых компонентов для работы системы логирования.
//
// Процесс инициализации:
// 1. Проверка и установка конфигурации по умолчанию при необходимости
// 2. Привязка к указанному blockstore для персистентного хранения
// 3. Настройка коллекции для хранения логов
// 4. Подготовка внутренних структур данных
//
// Параметры:
//
//	bs - экземпляр blockstore.Blockstore для хранения log записей в IPLD формате.
//	     Должен быть предварительно инициализирован и готов к работе.
//	config - конфигурация логгера. Если передан nil, будет использована конфигурация по умолчанию.
//	         Рекомендуется явно передавать конфигурацию для production использования.
//
// Возвращает:
//
//	Указатель на полностью инициализированный экземпляр OperationLog, готовый к использованию.
//
// Примеры использования:
//
//	// Простая инициализация с настройками по умолчанию
//	opLog := NewOperationLog(blockstore, nil)
//
//	// Инициализация с кастомной конфигурацией
//	config := &OperationLogConfig{
//	    Collection: "audit_logs",
//	    RetentionPeriod: 90 * 24 * time.Hour,
//	    EnabledOps: []string{"put_record", "delete_record"},
//	}
//	opLog := NewOperationLog(blockstore, config)
//
// Важные замечания:
// - blockstore должен поддерживать concurrent access для многопоточного использования
// - Конфигурация копируется при создании, последующие изменения не влияют на работу логгера
// - Экземпляр OperationLog thread-safe и может использоваться из нескольких горутин
func NewOperationLog(bs blockstore.Blockstore, config *OperationLogConfig) *OperationLog {
	if config == nil {
		config = DefaultOperationLogConfig()
	}

	return &OperationLog{
		bs:         bs,
		collection: config.Collection,
		config:     config,
	}
}

// LogOperation записывает информацию об операции в лог для аудита и мониторинга.
// Это основной метод для регистрации всех действий, выполняемых в системе.
//
// Алгоритм работы:
// 1. Проверка, включено ли логирование для данного типа операции
// 2. Валидация корректности и размера log entry
// 3. Конвертация entry в IPLD узел для стандартизированного хранения
// 4. Сохранение в blockstore с генерацией CID для верификации целостности
// 5. Опционально: добавление в batch или stream для оптимизации производительности
//
// Параметры:
//
//	ctx - контекст выполнения для управления временем жизни операции и отмены.
//	      Используется для graceful shutdown и таймаутов.
//	entry - указатель на структуру LogEntry с полной информацией об операции.
//	        Должна содержать все обязательные поля для успешной валидации.
//
// Возвращает:
//
//	error - ошибку, если операция не может быть записана в лог.
//	        nil при успешном сохранении записи.
//
// Возможные ошибки:
// - Операция отфильтрована конфигурацией (возвращает nil, молча пропускает)
// - Невалидная структура entry (отсутствуют обязательные поля)
// - Превышение максимального размера записи
// - Ошибки сериализации в IPLD формат
// - Ошибки записи в blockstore (проблемы с диском, сетью)
//
// Примеры использования:
//
//	// Логирование успешной операции создания записи
//	entry := &LogEntry{
//	    OperationID:   uuid.New().String(),
//	    Timestamp:     time.Now(),
//	    OperationType: OpPutRecord,
//	    Actor:         "did:plc:user123",
//	    Collection:    "app.bsky.feed.post",
//	    RKey:          "post123",
//	    RecordCID:     &recordCID,
//	    Result:        "success",
//	    Duration:      time.Since(startTime),
//	}
//	err := opLog.LogOperation(ctx, entry)
//
//	// Логирование неуспешной операции
//	entry.Result = "error"
//	entry.Error = "validation failed: missing required field"
//	err := opLog.LogOperation(ctx, entry)
//
// Производительность:
// - Операция выполняется синхронно в текущей реализации
// - В production рекомендуется асинхронная запись через goroutine pool
// - Batch запись может значительно улучшить throughput при высокой нагрузке
// - Streaming позволяет real-time мониторинг без влияния на производительность основных операций
//
// Безопасность:
// - Метод thread-safe и может вызываться из нескольких горутин одновременно
// - Не блокирует основные операции репозитория при ошибках логирования
// - Автоматическая валидация предотвращает некорректные записи
func (ol *OperationLog) LogOperation(ctx context.Context, entry *LogEntry) error {
	// Проверяем, включен ли данный тип операции
	if !ol.isOperationEnabled(entry.OperationType) {
		return nil // Молча пропускаем
	}

	// Валидируем размер entry
	if err := ol.validateEntry(entry); err != nil {
		return fmt.Errorf("invalid log entry: %w", err)
	}

	// Конвертируем в IPLD узел
	node, err := ol.entryToNode(entry)
	if err != nil {
		return fmt.Errorf("failed to convert entry to node: %w", err)
	}

	// Сохраняем запись (асинхронно в production версии)
	_, err = ol.bs.PutNode(ctx, node)
	if err != nil {
		return fmt.Errorf("failed to store log entry: %w", err)
	}

	// TODO: В production версии добавить:
	// 1. Batch записи для performance
	// 2. Async запись в background goroutine
	// 3. Streaming для real-time monitoring
	// 4. Periodic cleanup по retention policy
	// 5. Использовать rkey для хронологического ordering

	return nil
}

// QueryOperations выполняет поиск операций в логе по заданным критериям.
// Предоставляет мощный интерфейс для анализа и аудита действий в системе.
//
// Планируемая функциональность (в разработке):
// - Поиск по временному диапазону для анализа активности за период
// - Фильтрация по типу операции для специализированного анализа
// - Поиск по пользователю (Actor) для персонализированного аудита
// - Фильтрация по коллекции для анализа конкретных типов данных
// - Поиск по результату операции для выявления ошибок
// - Пагинация для обработки больших объемов данных
// - Сортировка по различным критериям
//
// Планируемые сценарии использования:
// - Аудит действий конкретного пользователя за период
// - Анализ ошибок и неуспешных операций
// - Мониторинг производительности операций
// - Генерация отчетов о активности системы
// - Поиск корреляций между различными типами операций
// - Восстановление последовательности действий для отладки
//
// Параметры:
//
//	ctx - контекст выполнения для управления таймаутами и отменой длительных запросов
//	query - критерии поиска, определяющие какие записи должны быть возвращены
//
// Возвращает:
//
//	[]*LogEntry - слайс найденных записей, отсортированных согласно критериям query
//	error - ошибку выполнения запроса или nil при успешном выполнении
//
// Планируемые оптимизации:
// - Индексирование по ключевым полям для быстрого поиска
// - Кэширование часто используемых запросов
// - Streaming результатов для больших наборов данных
// - Параллельное выполнение сложных запросов
//
// Текущий статус: НЕ РЕАЛИЗОВАНО
// TODO: Требует реализации системы индексации и query engine
func (ol *OperationLog) QueryOperations(ctx context.Context, query *LogQuery) ([]*LogEntry, error) {
	// TODO: Реализовать query interface для поиска операций
	// Возможные критерии поиска:
	// - Временной диапазон
	// - Тип операции
	// - Actor (пользователь)
	// - Collection
	// - Result (success/error)

	return nil, fmt.Errorf("query operations not implemented yet")
}

// GetOperationsStream создает поток для получения операций в реальном времени.
// Предназначен для систем мониторинга, аналитики и real-time обработки событий.
//
// Планируемая архитектура потокового интерфейса:
// - Pub/Sub модель для эффективной доставки событий
// - Буферизация для обработки пиковых нагрузок
// - Backpressure механизмы для предотвращения перегрузки
// - Фильтрация событий на уровне потока для оптимизации трафика
// - Гарантии доставки и порядка событий
// - Graceful reconnection при сбоях соединения
//
// Сценарии использования:
// - Real-time мониторинг активности пользователей
// - Живые дашборды с метриками системы
// - Автоматическое реагирование на критические события
// - Интеграция с внешними системами аналитики
// - Уведомления о подозрительной активности
// - Синхронизация между микросервисами
//
// Параметры:
//
//	ctx - контекст для управления жизненным циклом потока и graceful shutdown
//
// Возвращает:
//
//	<-chan *LogEntry - канал только для чтения, через который будут поступать новые операции
//	error - ошибку инициализации потока или nil при успешном создании
//
// Управление потоком:
// - Поток автоматически закрывается при отмене контекста
// - Клиент должен читать из канала для предотвращения блокировки
// - Поток доставляет только новые операции после момента подключения
// - Поддерживается множественные подписчики на один поток
//
// Планируемые настройки:
// - Размер буфера канала для контроля памяти
// - Фильтры по типу операции или пользователю
// - Режимы доставки (at-most-once, at-least-once)
// - Компрессия данных для экономии трафика
//
// Требования к конфигурации:
// - config.StreamEnabled должен быть true для работы потока
//
// Текущий статус: НЕ РЕАЛИЗОВАНО
// TODO: Требует реализации pub/sub инфраструктуры и event sourcing
func (ol *OperationLog) GetOperationsStream(ctx context.Context) (<-chan *LogEntry, error) {
	if !ol.config.StreamEnabled {
		return nil, fmt.Errorf("streaming not enabled")
	}

	// TODO: Реализовать streaming interface
	// Должен поддерживать:
	// - Real-time delivery новых операций
	// - Filtering по типу операции
	// - Backpressure handling

	return nil, fmt.Errorf("operations stream not implemented yet")
}

// Cleanup выполняет автоматическую очистку устаревших записей согласно политике хранения.
// Критически важен для управления размером логов и соблюдения требований к хранению данных.
//
// Алгоритм очистки:
// 1. Расчет времени cutoff на основе текущего времени и retention period
// 2. Идентификация записей старше cutoff времени
// 3. Опциональное архивирование критически важных записей
// 4. Пакетное удаление устаревших записей для оптимизации производительности
// 5. Обновление метрик и статистики использования места
// 6. Логирование результатов операции очистки
//
// Стратегии очистки:
// - Жесткое удаление: немедленное удаление без возможности восстановления
// - Мягкое удаление: пометка как удаленные с возможностью восстановления
// - Архивирование: перемещение в долгосрочное хранилище
// - Компрессия: сжатие старых записей для экономии места
//
// Параметры:
//
//	ctx - контекст выполнения для контроля времени выполнения и возможности отмены
//	      Важен для graceful shutdown во время длительных операций очистки
//
// Возвращает:
//
//	error - ошибку выполнения операции очистки или nil при успешном завершении
//
// Планируемая функциональность:
// - Пакетная обработка для минимизации влияния на производительность
// - Прогрессивная очистка с возможностью паузы и возобновления
// - Метрики очистки (количество удаленных записей, освобожденное место)
// - Уведомления администраторов о результатах очистки
// - Интеграция с системами резервного копирования
//
// Рекомендации по использованию:
// - Запускать в непиковые часы для минимального влияния на пользователей
// - Использовать cron или аналогичный планировщик для регулярного выполнения
// - Мониторить производительность и корректировать частоту выполнения
// - Настроить алерты при ошибках очистки
//
// Безопасность:
// - Операция необратима при жестком удалении
// - Рекомендуется предварительное тестирование на копии данных
// - Ведение собственного лога операций очистки
//
// Текущий статус: НЕ РЕАЛИЗОВАНО
// TODO: Требует реализации системы поиска по времени и batch удаления
func (ol *OperationLog) Cleanup(ctx context.Context) error {
	cutoffTime := time.Now().Add(-ol.config.RetentionPeriod)

	// TODO: Реализовать cleanup логики
	// 1. Найти записи старше cutoffTime
	// 2. Удалить их из blockstore
	// 3. Возможно, сначала архивировать

	_ = cutoffTime
	return fmt.Errorf("cleanup not implemented yet")
}

// isOperationEnabled проверяет, должна ли данная операция быть записана в лог.
// Используется для фильтрации операций согласно конфигурации и оптимизации производительности.
//
// Логика фильтрации:
// 1. Если EnabledOps пуст, разрешены все операции (backward compatibility)
// 2. Если содержит "all", логируются все типы операций
// 3. Иначе проверяется точное совпадение типа операции со списком разрешенных
//
// Сценарии использования:
// - Отключение логирования неважных операций в production
// - Логирование только критических операций для экономии места
// - Временное отключение логирования для отладки производительности
// - Специализированные логи для определенных типов операций
//
// Параметры:
//
//	opType - тип операции для проверки разрешения на логирование
//
// Возвращает:
//
//	bool - true если операция должна быть записана в лог, false для пропуска
//
// Производительность:
// - Оптимизирована для частого вызова (O(n) где n - количество включенных операций)
// - Рекомендуется кэширование результатов для высоконагруженных систем
// - Избегает аллокаций памяти для максимальной производительности
//
// Примеры конфигурации:
//
//	[]string{"all"} - логировать все операции
//	[]string{"put_record", "delete_record"} - только операции с записями
//	[]string{} - логировать все (по умолчанию)
//	[]string{"put_record"} - только создание записей
func (ol *OperationLog) isOperationEnabled(opType OperationType) bool {
	if len(ol.config.EnabledOps) == 0 {
		return true
	}

	for _, enabled := range ol.config.EnabledOps {
		if enabled == "all" || enabled == string(opType) {
			return true
		}
	}

	return false
}

// validateEntry выполняет комплексную валидацию log entry перед сохранением.
// Обеспечивает целостность данных и предотвращает сохранение некорректных записей.
//
// Проверки валидации:
// 1. Обязательные поля: OperationID, Timestamp, OperationType
// 2. Размер сериализованной записи не превышает MaxLogSize
// 3. Корректность формата временных меток
// 4. Валидность типа операции
// 5. Соответствие структуры данных ожидаемому формату
//
// Детали проверок:
// - OperationID: должен быть уникальным идентификатором (UUID рекомендуется)
// - Timestamp: не должен быть zero value, желательно в разумных пределах
// - OperationType: должен соответствовать одной из предопределенных констант
// - Размер: предотвращает создание чрезмерно больших записей, влияющих на производительность
//
// Параметры:
//
//	entry - указатель на LogEntry для валидации. Не изменяется в процессе проверки.
//
// Возвращает:
//
//	error - описание первой найденной ошибки валидации или nil если запись корректна
//
// Возможные ошибки:
// - "missing operation_id": отсутствует обязательный идентификатор операции
// - "missing timestamp": отсутствует временная метка операции
// - "missing operation_type": не указан тип операции
// - "entry size X exceeds maximum Y": размер записи превышает лимит
// - "failed to marshal entry": ошибка сериализации (указывает на проблемы в структуре)
//
// Производительность:
// - Сериализация выполняется только для проверки размера
// - Оптимизирована для частого использования
// - Минимальные аллокации памяти
//
// Безопасность:
// - Предотвращает DoS атаки через создание огромных записей
// - Обеспечивает согласованность структуры данных
// - Валидация выполняется до сохранения в blockstore
func (ol *OperationLog) validateEntry(entry *LogEntry) error {
	if entry.OperationID == "" {
		return fmt.Errorf("missing operation_id")
	}

	if entry.Timestamp.IsZero() {
		return fmt.Errorf("missing timestamp")
	}

	if entry.OperationType == "" {
		return fmt.Errorf("missing operation_type")
	}

	// Проверяем размер entry
	data, err := json.Marshal(entry)
	if err != nil {
		return fmt.Errorf("failed to marshal entry: %w", err)
	}

	if int64(len(data)) > ol.config.MaxLogSize {
		return fmt.Errorf("entry size %d exceeds maximum %d", len(data), ol.config.MaxLogSize)
	}

	return nil
}

// entryToNode конвертирует LogEntry в IPLD узел для стандартизированного хранения.
// Обеспечивает совместимость с IPFS экосистемой и верифицируемость данных через CID.
//
// Процесс конверсии:
// 1. Создание IPLD Map builder для структурированного представления
// 2. Последовательное добавление всех полей entry в соответствующем формате
// 3. Пропуск пустых и опциональных полей для оптимизации размера
// 4. Специальная обработка сложных типов (время, CID, metadata)
// 5. Финализация узла для получения immutable структуры
//
// Преобразования типов:
// - time.Time → Unix timestamp (int64) для кроссплатформенной совместимости
// - time.Duration → наносекунды (int64) для точности измерений
// - cid.Cid → строковое представление для сериализации
// - OperationType → строка для читаемости
// - Пустые строки пропускаются для экономии места
//
// Параметры:
//
//	entry - указатель на LogEntry для конверсии. Данные не изменяются.
//
// Возвращает:
//
//	datamodel.Node - IPLD узел, готовый для сохранения в blockstore
//	error - ошибку конверсии или nil при успешном преобразовании
//
// Возможные ошибки:
// - Ошибки создания IPLD builder (нехватка памяти)
// - Ошибки добавления полей (некорректные типы данных)
// - Ошибки финализации узла (внутренние ошибки IPLD)
//
// Особенности реализации:
// - Поля error и record_cid добавляются условно для оптимизации
// - metadata поле пока не реализовано (требует nested map support)
// - Порядок полей детерминирован для консистентности CID
// - Использует базовые типы IPLD для максимальной совместимости
//
// TODO: Планируемые улучшения:
// - Полная поддержка metadata как nested map
// - Оптимизация размера через custom IPLD codec
// - Валидация схемы IPLD для гарантии корректности
// - Поддержка версионирования формата записей
func (ol *OperationLog) entryToNode(entry *LogEntry) (datamodel.Node, error) {
	builder := basicnode.Prototype.Map.NewBuilder()
	ma, err := builder.BeginMap(10) // Количество полей
	if err != nil {
		return nil, err
	}

	// Добавляем все поля entry
	fields := map[string]interface{}{
		"operation_id":   entry.OperationID,
		"timestamp":      entry.Timestamp.Unix(),
		"operation_type": string(entry.OperationType),
		"actor":          entry.Actor,
		"collection":     entry.Collection,
		"rkey":           entry.RKey,
		"result":         entry.Result,
		"error":          entry.Error,
		"duration":       entry.Duration.Nanoseconds(),
	}

	for key, value := range fields {
		if value == "" || (key == "error" && entry.Result != "error") {
			continue // Пропускаем пустые поля
		}

		entry, err := ma.AssembleEntry(key)
		if err != nil {
			return nil, err
		}

		switch v := value.(type) {
		case string:
			if err := entry.AssignString(v); err != nil {
				return nil, err
			}
		case int64:
			if err := entry.AssignInt(v); err != nil {
				return nil, err
			}
		}
	}

	// Добавляем record_cid если есть
	if entry.RecordCID != nil {
		cidEntry, err := ma.AssembleEntry("record_cid")
		if err != nil {
			return nil, err
		}
		if err := cidEntry.AssignString(entry.RecordCID.String()); err != nil {
			return nil, err
		}
	}

	// TODO: Добавить metadata поле как nested map

	if err := ma.Finish(); err != nil {
		return nil, err
	}

	return builder.Build(), nil
}

// LogQuery определяет критерии поиска для выполнения запросов к логу операций.
// Предоставляет гибкий интерфейс для фильтрации и получения нужных записей.
//
// Архитектура запросов:
// - Комбинирование множественных критериев через логическое И (AND)
// - Опциональные поля позволяют строить специфические запросы
// - Поддержка временных диапазонов для анализа активности за период
// - Пагинация для эффективной обработки больших результатов
//
// Сценарии использования:
// - Аудит действий конкретного пользователя за определенный период
// - Поиск всех ошибок в системе за последний день
// - Анализ операций с конкретной коллекцией
// - Мониторинг производительности определенных типов операций
// - Генерация отчетов о активности системы
//
// Оптимизация запросов:
// - StartTime и EndTime создают временное окно для эффективного поиска
// - Индексы по OperationType и Actor ускоряют фильтрацию
// - Limit предотвращает перегрузку при больших результатах
// - Offset обеспечивает постраничную навигацию
//
// Примеры типичных запросов:
//
//	// Все операции пользователя за последний час
//	&LogQuery{
//	    StartTime: &oneHourAgo,
//	    EndTime: &now,
//	    Actor: "did:plc:user123",
//	    Limit: 100,
//	}
//
//	// Все ошибки создания записей за сегодня
//	&LogQuery{
//	    StartTime: &todayStart,
//	    OperationType: &OpPutRecord,
//	    Result: "error",
//	    Limit: 50,
//	}
//
//	// Операции с конкретной коллекцией
//	&LogQuery{
//	    Collection: "app.bsky.feed.post",
//	    Limit: 200,
//	    Offset: 0,
//	}
type LogQuery struct {
	StartTime     *time.Time     `json:"start_time"`     // Начало временного диапазона для поиска (включительно). nil означает "с самого начала"
	EndTime       *time.Time     `json:"end_time"`       // Конец временного диапазона для поиска (включительно). nil означает "до текущего момента"
	OperationType *OperationType `json:"operation_type"` // Фильтр по типу операции. nil означает "все типы операций"
	Actor         string         `json:"actor"`          // DID пользователя для фильтрации. Пустая строка означает "все пользователи"
	Collection    string         `json:"collection"`     // Имя коллекции для фильтрации. Пустая строка означает "все коллекции"
	Result        string         `json:"result"`         // Фильтр по результату операции: "success", "error" или пустая строка для всех
	Limit         int            `json:"limit"`          // Максимальное количество возвращаемых результатов (по умолчанию: 100, максимум: 10000)
	Offset        int            `json:"offset"`         // Смещение для пагинации результатов (начинается с 0)
}

// ИНТЕГРАЦИЯ С REPOSITORY:
//
// Repository должен вызывать OperationLog.LogOperation() для каждой операции:
//
// func (r *Repository) PutRecord(ctx context.Context, collection, rkey string, node datamodel.Node) (cid.Cid, error) {
//     start := time.Now()
//     opID := generateOperationID()
//
//     // Выполняем основную операцию
//     recordCID, err := r.datastore.Put(ctx, ...)
//
//     // Логируем операцию
//     entry := &LogEntry{
//         OperationID:   opID,
//         Timestamp:     start,
//         OperationType: OpPutRecord,
//         Actor:         r.getCurrentActor(ctx),
//         Collection:    collection,
//         RKey:          rkey,
//         RecordCID:     &recordCID,
//         Duration:      time.Since(start),
//         Result:        "success",
//     }
//
//     if err != nil {
//         entry.Result = "error"
//         entry.Error = err.Error()
//     }
//
//     if logErr := r.operationLog.LogOperation(ctx, entry); logErr != nil {
//         // Логируем ошибку, но не прерываем основную операцию
//         fmt.Printf("Failed to log operation: %v\n", logErr)
//     }
//
//     return recordCID, err
// }

// ПРИМЕР ИСПОЛЬЗОВАНИЯ:
//
// // Создание operation log
// opLog := NewOperationLog(blockstore, &OperationLogConfig{
//     Collection:      "audit_log",
//     RetentionPeriod: 90 * 24 * time.Hour, // 90 days
//     EnabledOps:      []string{"put_record", "delete_record"},
//     StreamEnabled:   true,
// })
//
// // Интеграция с repository
// repo := NewRepository(datastore, lexicon, opLog)
//
// // Query операций
// query := &LogQuery{
//     StartTime:     &startTime,
//     EndTime:       &endTime,
//     OperationType: &OpPutRecord,
//     Collection:    "app.bsky.feed.post",
// }
//
// operations, err := opLog.QueryOperations(ctx, query)
//
// // Streaming операций
// stream, err := opLog.GetOperationsStream(ctx)
// for entry := range stream {
//     fmt.Printf("Operation: %s on %s\n", entry.OperationType, entry.Collection)
// }
